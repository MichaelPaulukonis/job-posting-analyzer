# AWS Migration Plan: Firebase Auth + Storage → AWS Stack

## Problem Statement

The Job Posting Analyzer currently uses Firebase Auth and persists data locally in JSON files (`.data/` directory). While this works for single-user development, the existing data structure needs migration to a proper database to support production deployment, multi-device access, and advanced features like vector-based semantic search. Firebase doesn't support pgvector (critical for semantic job matching), making AWS a better fit. Additionally, the user wants to deepen AWS knowledge and create a portfolio-worthy deployment.

## Current State

- **Authentication**: Firebase Auth (email/password)
- **Storage**: Local JSON files in `.data/` directory:
  - `resumes.json` - Resume versions with id, name, content, timestamp  
  - `analysis-history.json` - Analysis results with matches, gaps, suggestions
  - `conversations.json` - AI conversation context for cover letters
  - `cover-letter-samples.json` - Cover letter templates and versions
- **Storage Service**: `FileStorageService` class providing CRUD operations on JSON files
- **Analysis Feature**: Working (resume vs job posting comparison)
- **Deployment**: Local development only  
- **User Base**: Single user (public portfolio app)

## Goals

1. **Migrate to AWS** for hosting and persistent storage
2. **Enable vector search** with pgvector for semantic job matching
3. **Maintain Firebase Auth** (simple, already working) OR migrate to Cognito
4. **Create portfolio-worthy AWS architecture** demonstrating:
   - Modern Nuxt 3 deployment on App Runner
   - PostgreSQL with pgvector for semantic search
   - S3 for file storage
   - Clean API design with Nitro
5. **Support future features**:
   - Store analysis history
   - Save favorite job postings
   - Vector-based job recommendations
   - Resume versions

## Technical Approach

### Architecture Overview

```
┌─────────────────────────────────────────────┐
│         Nuxt 3 Frontend Application         │
│  (Components, Pages, Analysis Logic)        │
└──────────────────┬──────────────────────────┘
                   │
        ┌──────────┴──────────┐
        │                     │
        ▼                     ▼
   ┌─────────┐        ┌────────────┐
   │Firebase │        │AWS App     │
   │Auth     │        │Runner      │
   │(Keep)   │        │(Nuxt SSR)  │
   └─────────┘        └──────┬─────┘
                             │
                      ┌──────┴──────┐
                      │             │
                      ▼             ▼
                   ┌──────┐    ┌──────────┐
                   │ S3   │    │RDS PgSQL │
                   │Files │    │+pgvector │
                   └──────┘    └──────────┘
```

### Services Selection

| Component | Service | Rationale |
|-----------|---------|-----------|
| **Hosting** | AWS App Runner | Container-native, Nuxt-friendly, minimal DevOps, auto-scaling |
| **Database** | RDS PostgreSQL | Relational data, pgvector for embeddings, complex queries |
| **Storage** | S3 | Cheap file storage, resume/document PDFs |
| **Authentication** | Firebase Auth (keep) | Already working, simple, no migration friction |
| **Embeddings** | Gemini/Claude APIs (existing) | Already integrated, no change needed |

### Data Model (Postgres)

```sql
-- Users table
CREATE TABLE users (
  id UUID PRIMARY KEY,
  firebase_uid VARCHAR(255) UNIQUE NOT NULL,
  email VARCHAR(255) UNIQUE NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);

-- Resumes
CREATE TABLE resumes (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id),
  name VARCHAR(255),
  content TEXT,
  s3_url VARCHAR(512),
  created_at TIMESTAMP DEFAULT NOW()
);

-- Job Postings
CREATE TABLE job_postings (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id),
  title VARCHAR(255),
  company VARCHAR(255),
  content TEXT,
  embedding vector(1536),  -- For semantic search (pgvector)
  created_at TIMESTAMP DEFAULT NOW()
);

-- Analysis Results
CREATE TABLE analysis_results (
  id UUID PRIMARY KEY,
  user_id UUID REFERENCES users(id),
  resume_id UUID REFERENCES resumes(id),
  job_posting_id UUID REFERENCES job_postings(id),
  matches JSONB,          -- Skills matched
  gaps JSONB,             -- Missing skills
  suggestions JSONB,      -- Recommendations
  created_at TIMESTAMP DEFAULT NOW()
);
```

### Migration Steps

#### Phase 1: AWS Account & RDS Setup (Week 1)
- [ ] Create/configure AWS account (or use existing)
- [ ] Set up IAM user with appropriate permissions
- [ ] Create RDS PostgreSQL instance (db.t4g.micro for learning)
- [ ] Enable pgvector extension
- [ ] Create database schema (designed to preserve current JSON structure)
- [ ] Build data migration script to import from `.data/` JSON files:
  - Migrate `resumes.json` → `resumes` table
  - Migrate `analysis-history.json` → `analysis_results` table
  - Migrate `conversations.json` → preserve as JSONB or separate table
  - Migrate `cover-letter-samples.json` → related tables
- [ ] Generate AWS credentials, store in `.env`

#### Phase 2: Storage & API Layer (Week 2)
- [ ] Set up S3 bucket for resume/file storage
- [ ] Create S3 access IAM policy
- [ ] Build Nitro API routes:
  - `POST /api/auth/profile` - Sync Firebase user to Postgres
  - `POST /api/resumes` - Upload resume to S3, store metadata
  - `POST /api/job-postings` - Save job posting with embedding
  - `GET /api/analysis/:id` - Retrieve stored analysis
  - `POST /api/analysis` - Create analysis, store results
- [ ] Update services to use RDS instead of in-memory state
- [ ] Implement Firebase token validation on backend

#### Phase 3: Containerization (Week 3)
- [ ] Create Dockerfile (with node:20-alpine, multi-stage build)
- [ ] Create docker-compose.yml for local testing
- [ ] Build and test container locally
- [ ] Push to AWS ECR (Elastic Container Registry)

#### Phase 4: Deploy to App Runner (Week 4)
- [ ] Create App Runner service
- [ ] Configure environment variables (RDS connection string, S3 bucket, etc.)
- [ ] Set up auto-scaling policies
- [ ] Configure health checks
- [ ] Test production deployment
- [ ] Set up domain (optional: Route 53 or Vercel alias)

#### Phase 5: Enhancements (Ongoing)
- [ ] Add vector search endpoints (`GET /api/jobs/similar?embedding=...`)
- [ ] Implement analysis history UI
- [ ] Add ability to save/favorite job postings
- [ ] Resume versioning

### Technology Stack

| Layer | Technology | Version |
|-------|-----------|---------|
| **Frontend** | Vue 3 + Nuxt | 3.x |
| **Backend** | Nitro (Nuxt server) | Built-in |
| **Database** | PostgreSQL | 15+ |
| **Vector Search** | pgvector | Latest |
| **Auth** | Firebase Auth | Keep existing |
| **Storage** | AWS S3 | Via SDK |
| **Container** | Docker | 24+ |
| **Deployment** | AWS App Runner | - |
| **ORM** (optional) | Drizzle or Prisma | v4+ |

### Dependencies to Add

```json
{
  "@aws-sdk/client-s3": "^3.x",
  "@aws-sdk/client-rds": "^3.x",
  "pg": "^8.x",
  "pgvector": "^0.x",
  "prisma": "^5.x"  // OR drizzle-orm
}
```

## Implementation Steps

### Step 1: Database Setup
1. Create RDS instance
2. Run migrations (SQL scripts)
3. Test connection from local machine

### Step 2: Services Layer
1. Create `server/services/DatabaseService.ts` - Connection pooling
2. Create `server/services/S3Service.ts` - File upload/download
3. Update `services/AnalysisService.ts` to store results in DB

### Step 3: API Endpoints
Create Nitro API routes:
- `server/api/auth/profile.post.ts` - Sync user
- `server/api/resumes.post.ts` - Upload resume
- `server/api/job-postings.post.ts` - Save job posting
- `server/api/analysis.post.ts` - Store analysis
- `server/api/analysis/[id].get.ts` - Retrieve analysis

### Step 4: Frontend Updates
1. Update analysis page to save results
2. Create history page showing past analyses
3. Add resume management page

### Step 5: Deployment
1. Build Docker image
2. Push to ECR
3. Create App Runner service
4. Configure DNS/domain

## Testing Strategy

### Unit Tests
- Database connection pooling
- S3 upload/download functions
- API endpoint validation
- Vector search queries

### Integration Tests
- End-to-end analysis flow (resume → job posting → storage → retrieval)
- User auth sync (Firebase → Postgres)
- File upload pipeline (frontend → S3 → metadata in DB)

### Manual Testing
- Deploy to staging environment
- Test with multiple job postings
- Verify vector search results
- Test portfolio sharing

## Risks & Mitigation

| Risk | Impact | Mitigation |
|------|--------|-----------|
| **RDS costs exceed budget** | Medium | Use t4g.micro (free tier eligible), monitor CloudWatch |
| **Firebase Auth migration issues** | Medium | Keep Firebase Auth, only move data layer |
| **Container image too large** | Low | Multi-stage Dockerfile, prune dependencies |
| **Vector embeddings incompatible** | Low | Test with existing Gemini/Anthropic API format |
| **Cold start latency** | Low | App Runner handles, no Lambda cold starts |
| **Data migration from Firebase** | Medium | Plan export strategy, no current data to migrate |

## Success Criteria

- ✅ Application runs on AWS App Runner
- ✅ Resumes/job postings stored in RDS
- ✅ Analysis history persisted and retrievable
- ✅ Vector search working for similar job postings
- ✅ Firebase Auth still functioning
- ✅ Portfolio app public and shareable
- ✅ All tests passing
- ✅ Infrastructure-as-code documentation updated

## Dependencies & Prerequisites

- AWS Account (with free tier eligibility preferred)
- AWS CLI configured locally
- Docker installed locally
- Existing Firebase project (auth only)
- Gemini/Anthropic API keys (already have)

## Timeline

- **Week 1**: AWS setup, RDS, basic schema
- **Week 2**: API layer, S3 integration
- **Week 3**: Containerization, local testing
- **Week 4**: App Runner deployment
- **Week 5+**: Enhancements, monitoring, optimization

**Total**: 3-4 weeks for core migration, ongoing for features

## Notes

- This migration can happen incrementally; the app continues to work during transition
- Firebase Auth can stay indefinitely; no rush to migrate to Cognito
- Vector search is optional but adds significant value for "similar jobs" features
- This project is a strong portfolio piece demonstrating full-stack AWS

## Future Enhancements (Post-Migration)

1. **AWS Cognito** - Replace Firebase Auth (optional, more AWS-integrated)
2. **AWS Bedrock** - Managed embeddings instead of API calls
3. **Lambda Functions** - Async job processing for large uploads
4. **CloudFront** - CDN for static assets
5. **ElastiCache** - Caching for frequent queries
6. **DynamoDB** - NoSQL for analysis session data (if needed)
7. **SNS/SQS** - Email notifications on analysis completion
8. **CloudWatch** - Enhanced monitoring and alerts
