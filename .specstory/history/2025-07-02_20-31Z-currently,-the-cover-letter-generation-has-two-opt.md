<!-- Generated by SpecStory -->

# Currently, the cover-letter generation has two opt (2025-07-02 20:31Z)

_**User**_

Currently, the cover-letter generation has two options - generate a letter using a sample letter + resume + analysis, or generate a letter using previous generation + additional prompt + resume + analysis. The problem here is that the context is lost on subsequent prompts. The first additional prompt is fine, that's iterating on the letter and adding something new. But if we iterate again, the context of the first prompt is lost. This is an issue as I instruct the LLMs to remove non-factual language, only to see it reappear when the context is lost.

I believe this is a "solved problem" in conversational AI systems, and keeping a context of multiple prompts and responses is essentially a conversation. I am not sure what libraries or patterns should be used to do this. Please advise on 2 or more approaches, listing the pros and cons of each.

---

_**Assistant**_

You're absolutely right - this is a classic context management problem in conversational AI systems. Let me outline several approaches with their pros and cons:

## Approach 1: Conversation History Array

Store the entire conversation history and pass it to the LLM on each iteration.

**Implementation:**
- Maintain an array of `{role: 'user'|'assistant', content: string}` messages
- Send full conversation history with each new request
- Most LLM APIs support this pattern natively

**Pros:**
- Simple to implement
- Preserves full context
- Native support in most LLM APIs (OpenAI, Claude, Gemini)
- No external dependencies

**Cons:**
- Token usage grows linearly with conversation length
- Can hit token limits on long conversations
- Higher costs due to repeated context

## Approach 2: Context Summarization with Key Points

Maintain a running summary of key instructions and decisions while keeping recent messages.

**Implementation:**
- Keep last N messages in full
- Maintain a summary of key points from earlier messages
- Compress older context into structured summaries

**Pros:**
- Balances context preservation with token efficiency
- Scales better for long conversations
- Can preserve specific instructions (like "avoid flowery language")

**Cons:**
- More complex to implement
- Risk of losing important nuances in summarization
- Requires careful prompt engineering for summaries

## Approach 3: Instruction Accumulation Pattern

Build up a persistent "instruction set" that grows with each iteration.

**Implementation:**
- Extract and accumulate explicit instructions from each user prompt
- Maintain them as a separate context section
- Combine with current request

**Pros:**
- Preserves specific user preferences
- Efficient token usage
- Clear separation of instructions vs. content

**Cons:**
- May miss implicit context
- Requires parsing user instructions accurately
- Could lead to contradictory instructions over time

## Approach 4: Hybrid Context Window Management

Combine conversation history with intelligent truncation and instruction preservation.

**Implementation:**
- Always preserve system instructions and user preferences
- Keep recent 

---

_**User**_

Currently, the cover-letter generation has two options - generate a letter using a sample letter + resume + analysis, or generate a letter using previous generation + additional prompt + resume + analysis. The problem here is that the context is lost on subsequent prompts. The first additional prompt is fine, that's iterating on the letter and adding something new. But if we iterate again, the context of the first prompt is lost. This is an issue as I instruct the LLMs to remove non-factual language, only to see it reappear when the context is lost.

I believe this is a "solved problem" in conversational AI systems, and keeping a context of multiple prompts and responses is essentially a conversation. I am not sure what libraries or patterns should be used to do this. Please advise on 2 or more approaches, listing the pros and cons of each.

---

_**Assistant**_



---

